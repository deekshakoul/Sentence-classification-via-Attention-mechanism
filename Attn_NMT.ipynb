{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attn_NMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deekshakoul/Sentence-classification-via-Attention-mechanism/blob/main/Attn_NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgqK6l94ss8W"
      },
      "source": [
        "-- Pictorial representation of how to have a simple attention mechanism applied to text-classification --\r\n",
        "\r\n",
        "\r\n",
        "![g.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAGZxgfNr0gn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "062265ce-e9e0-4eb9-f6e1-b6dc102e51ee"
      },
      "source": [
        "!git clone https://github.com/deekshakoul/sent-conv-torch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sent-conv-torch'...\n",
            "remote: Enumerating objects: 477, done.\u001b[K\n",
            "remote: Total 477 (delta 0), reused 0 (delta 0), pack-reused 477\u001b[K\n",
            "Receiving objects: 100% (477/477), 58.85 MiB | 33.65 MiB/s, done.\n",
            "Resolving deltas: 100% (309/309), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IYcelOKird7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "60b0a6fc-a82c-4dbc-9057-59df44f9208f"
      },
      "source": [
        "import re,string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import copy\n",
        "#=========================pytorch========================#\n",
        "import torch   \n",
        "from torchtext import data ,vocab\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "SEED = 134\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True  \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
        "print(\"cuda? \",torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "cuda?  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu0LZc9Rlf8M"
      },
      "source": [
        "def clean_str(string):\n",
        "  string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n",
        "  string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
        "  string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
        "  string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n",
        "  string = re.sub(r\"\\'re\", \" \\'re\", string) \n",
        "  string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
        "  string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
        "  string = re.sub(r\",\", \" , \", string) \n",
        "  string = re.sub(r\"!\", \" ! \", string) \n",
        "  string = re.sub(r\"\\(\", \" ( \", string) \n",
        "  string = re.sub(r\"\\)\", \" ) \", string) \n",
        "  string = re.sub(r\"\\?\", \" ? \", string) \n",
        "  string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
        "  return string.strip().lower()\n",
        "\n",
        "def create_df(filename):\n",
        "  with open(filename,'rb') as f: #MR\n",
        "    q = f.readlines()\n",
        "  texts=[]\n",
        "  for i in range(len(q)):\n",
        "    # print(i)\n",
        "    texts.append(q[i].decode('latin-1'))\n",
        "  ###################create dataframe##########################\n",
        "  df = pd.DataFrame(texts, columns=['text'])\n",
        "  df['label'] = df['text']\n",
        "  df['label'] =df['label'].apply(lambda s: s.split(\" \")[0])\n",
        "  df['text']=df['text'].apply(lambda s: s[1:])\n",
        "  df['label'] = df['label'].astype(int)\n",
        "  return df  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1dswNMzCRvv"
      },
      "source": [
        "data_p = \"/content/sent-conv-torch/data/\"\n",
        "def create_alldata_csv(fname):\n",
        "  ''' \n",
        "      Read from file\n",
        "      create dataframe, appply pre-processing from RP\n",
        "      save all data to csv \n",
        "  '''\n",
        "  path=os.path.join(data_p,fname)\n",
        "  print(path)\n",
        "  df = create_df(path)\n",
        "  df['text'] = df['text'].apply(clean_str)\n",
        "\n",
        "  #remove zero length texts\n",
        "  ll = list(df[\"text\"].apply(lambda s: len(s)))\n",
        "  inds = [ i for i in range(len(ll)) if ll[i]==0]\n",
        "  df = df.drop(index=inds)\n",
        "  df.to_csv(\"fulldata.csv\",index=False)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61Sh1zaXEKZr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "14b73712-cdf8-4f53-8560-1dab40c6d482"
      },
      "source": [
        "df = create_alldata_csv('rt-polarity.all') \n",
        "#subj.all , custrev.all , rt-polarity.all , mpqa.all\n",
        "df=df.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sent-conv-torch/data/rt-polarity.all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wziJnjZpGuv"
      },
      "source": [
        "!head \"fulldata.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWU1tPqzpFp9"
      },
      "source": [
        "TEXT = data.Field(lower=True,batch_first=True,include_lengths=True)#,stop_words=stop), tokenize='spacy',\n",
        "LABEL = data.LabelField(dtype = torch.int,batch_first=True)\n",
        "fields = [('text',TEXT),('label', LABEL)]\n",
        "all_data = data.TabularDataset(skip_header = True,path='/content/fulldata.csv',format = 'csv', fields=fields)\n",
        "#print(vars(valid_data.examples[190]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ly5UX9iE296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ae3fefcc-c499-4ec5-b40b-ddd2d5b5ffbb"
      },
      "source": [
        "######################Dont run again and again###########################\n",
        "!cp /content/drive/My\\ Drive/datasets/glove.840B.300d.zip /content\n",
        "!unzip /content/glove.840B.300d.zip\n",
        "import os\n",
        "emb_path = '/content'\n",
        "vec = vocab.Vectors(os.path.join(emb_path, 'glove.840B.300d.txt'), cache=emb_path,unk_init = torch.Tensor.normal_)\n",
        "#unk_init (callback): by default, initialize out-of-vocabulary word vectors to zero vectors;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 2195759/2196017 [04:01<00:00, 9514.32it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYM3yStzI2sm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "b9629267-16b3-4b62-b5c0-871f8e3f033d"
      },
      "source": [
        "TEXT.build_vocab(all_data,vectors = vec ) #all_data has tokens(words) and they will be mapped to embeddings of glove..if word is in glove\n",
        "LABEL.build_vocab(all_data)\n",
        "word_embeddings = TEXT.vocab.vectors\n",
        "word_embeddings[1] = torch.zeros(word_embeddings.shape[1])\n",
        "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab)) #total words\n",
        "print(\"===========\\n\",TEXT.vocab.vectors)\n",
        "#u will notice <UNK>:0 and <PAD>:1 initialized randomly.....rest words or indices will always remain same"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of TEXT vocabulary: 18767\n",
            "===========\n",
            " tensor([[-0.0915, -1.2666,  0.8834,  ...,  0.3752, -1.2412, -1.3260],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.2720, -0.0620, -0.1884,  ...,  0.1302, -0.1832,  0.1323],\n",
            "        ...,\n",
            "        [-0.0029, -0.4766, -0.1945,  ..., -0.0704,  0.6770,  0.4400],\n",
            "        [ 0.1710,  0.2598, -0.4678,  ...,  0.0272, -0.0048, -0.1162],\n",
            "        [ 0.8430, -0.0559, -0.0837,  ...,  0.9208, -0.2708, -0.4322]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbEG8683vzo"
      },
      "source": [
        "print(TEXT.vocab.stoi)\n",
        "dd = TEXT.vocab.stoi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF7M_KKuK0Sp"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "cv = 10\n",
        "kf = StratifiedKFold(cv, True, SEED)\n",
        "\n",
        "folds=[]\n",
        "for tr, tt in kf.split(df[\"text\"], df[\"label\"]):\n",
        "    #print(train_index, test_index)\n",
        "    #print(len(train_index), len(test_index))\n",
        "    folds.append((list(tr), list(tt)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiDtJR6vlLzl"
      },
      "source": [
        "global testing\n",
        "testing =  False\n",
        "global attn_wts_test;\n",
        "clip=1e-3\n",
        "batch = 16\n",
        "EPOCHS = 200\n",
        "'''lrate = 0.2e-5\n",
        "wd =3e-6'''\n",
        "lrate = 0.5e-5\n",
        "wd =1e-6\n",
        "parms=[clip,batch,EPOCHS,lrate,wd]\n",
        "#wd is generally higher than lr\n",
        "#a higher lr will be bad\n",
        "fold_scores = []\n",
        "# test_loss = []\n",
        "test_loss_fold=[]\n",
        "tr_loss_fold=[]\n",
        "flag=True\n",
        "ffd=0\n",
        "best_acc_overall =0\n",
        "for i, (tr_ix, tt_ix) in enumerate(folds):\n",
        "  print(\"Fold ==> \",i+1)\n",
        "  train_data = [item for i,item in enumerate(all_data) if i in tr_ix]\n",
        "  test_data = [item for i,item in enumerate(all_data) if i in tt_ix]\n",
        "  train = data.Dataset(train_data,fields)\n",
        "  test = data.Dataset(test_data,fields)\n",
        "  print(\"train size: \", len(train_data), \" and test size: \", len(test_data))\n",
        "  print(\"how many training ex.s skipped \",divmod(len(train_data),batch)[1],\"how many test ex.s skipped \",divmod(len(test_data),batch)[1])\n",
        "  train_itr, test_itr  = data.BucketIterator.splits(\n",
        "                (train, test), \n",
        "                batch_size = batch,\n",
        "                sort_key = lambda x: len(x.text),\n",
        "                sort_within_batch=True,\n",
        "                device = device,\n",
        "                shuffle=True\n",
        "              )   \n",
        "  model = build_model(word_embeddings) #initilize mlodel object along with pretrained embeddings\n",
        "  print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "  \n",
        "  #################WEIGHT INITIALIZATION###########################\n",
        "  model.apply(weights_init_N)\n",
        "  model.embedding.weight.data.copy_(word_embeddings) #vocab x embed_dim\n",
        "  model.embedding.weight.data[1] = torch.zeros(300)\n",
        "  \n",
        "  criterion = build_criterion()\n",
        "  \n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=lrate, weight_decay=wd) # some of the parameters you give the optimizer do not require gradients, and so he don’t know how to handle them\n",
        "\n",
        "  best_acc = 0.0\n",
        "  best_loss = 100.0\n",
        "  test_loss = []\n",
        "  tr_loss = []\n",
        "  test_acc = []\n",
        "  tr_acc = []\n",
        "  for ep in range(EPOCHS):\n",
        "    train_loss, train_acc = training(model,train_itr,criterion,batch, optimizer,clip=clip)\n",
        "    eval_loss, eval_acc = evaluation(model,test_itr,batch)\n",
        "    print(f'Epoch: {ep+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f} %, Test Loss: {eval_loss:3f}, test Acc: {eval_acc:.2f}%')\n",
        "    test_loss.append(eval_loss)\n",
        "    tr_loss.append(train_loss)\n",
        "    test_acc.append(eval_acc)\n",
        "    tr_acc.append(train_acc)\n",
        "    if eval_acc > best_acc:\n",
        "      best_acc = eval_acc\n",
        "      best_acc_ep = ep\n",
        "      best_acc_loss = eval_loss\n",
        "      ffd=i\n",
        "    if eval_loss < best_loss:\n",
        "      best_loss = eval_loss\n",
        "      best_loss_ep = ep\n",
        "      best_loss_acc = eval_acc\n",
        "\n",
        "  if  best_acc_overall < best_acc:  #best_acc is for every fold\n",
        "    best_acc_overall = best_acc\n",
        "    model_copy = copy.deepcopy(model)\n",
        "    print(\"For fold \",i+1,\" given \",cv,\" folds\", \" best accuracy for this fold is  \",best_acc)\n",
        "\n",
        "\n",
        "  plot_losses_per_fold(tr_loss,test_loss,i+1)\n",
        "  plot_losses_per_fold(tr_acc,test_acc,i+1,\"ACC\")\n",
        "\n",
        "  fold_scores.append((i,best_acc_ep,best_acc,best_acc_loss,i,best_loss_ep,best_loss,best_loss_acc))\n",
        "\n",
        "parms.extend([best_acc_ep,best_acc,best_acc_loss,ffd])\n",
        "\n",
        "#the model with max accuarcy OVER all folds is stored\n",
        "\n",
        "model_params(parms)\n",
        "print(dfp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LFg6n2VeVUH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cac098fd-ece1-43f6-a811-740b66bc5c1e"
      },
      "source": [
        "best_acc_overall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.42664670658682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtGg3-2Xa5Ap"
      },
      "source": [
        "def plot_losses_per_fold(tr, tt,fold,c=\"LOSS\"):\n",
        "  epoch_count = range(1, len(tr) + 1)\n",
        "  name = 'MR' + \"_CV\" + str(fold)  + \"_\" + c\n",
        "  plt.plot(epoch_count, tr, 'r--')\n",
        "  plt.plot(epoch_count, tt, 'b-')\n",
        "  if c == \"LOSS\":\n",
        "    plt.legend(['Training Loss', 'Test Loss'])\n",
        "  else:\n",
        "    plt.legend(['Training Accuracy', 'Test Accuracy'])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss') \n",
        "  if c==\"ACC\":\n",
        "    plt.ylabel('Accuracy') \n",
        "  \n",
        "  plt.xticks(np.arange(min(epoch_count), max(epoch_count)+1, 40.0))\n",
        "  # plt.ylim(-5, 5)\n",
        "  plt.savefig(name)\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Yll2lkUHS6"
      },
      "source": [
        "acc_folds = [fold_scores[i][2] for i in range(len(fold_scores))]\n",
        "mean_acc = sum(acc_folds)/len(fold_scores)\n",
        "print(mean_acc)\n",
        "acc_folds = [fold_scores[i][2] for i in range(len(fold_scores))]\n",
        "print(acc_folds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewjITXElrnGC"
      },
      "source": [
        "---TESTING----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg-lsqrR-BW9"
      },
      "source": [
        "dd = TEXT.vocab.stoi\n",
        "k = list(dd.keys())\n",
        "v = list(dd.values())\n",
        "def get_sent(text):\n",
        "  sent=[]  \n",
        "  for i in text:\n",
        "    sent.append(k[v.index(i)])\n",
        "  return sent\n",
        "def get_indices_sent(text):\n",
        "  ind=[]\n",
        "  tokens = text.split()\n",
        "  for i in range(len(tokens)):  \n",
        "    if tokens[i] in k:\n",
        "      ind.append(dd[tokens[i]])\n",
        "    else:\n",
        "      ind.append(TEXT.vocab.stoi[TEXT.unk_token])\n",
        "  return ind      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLLjqQI04cIp"
      },
      "source": [
        "# sentences = [\"interesting , but not compelling\", \"good movie good  music\", \"loved the script \", 'loved the movie', 'loving script','silly movie']\n",
        "sentences = [\"light , cute and forgettable\"]\n",
        "##\"interesting , but not compelling\"\n",
        "\n",
        "#sentences = [ \"what is the percentage of water in human body\" , \"what articles of clothing are tokens in monopoly\"]#TREC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqaYu2IwCfAE"
      },
      "source": [
        "txt, txt_len = make_batch(sentences)\n",
        "testing = True\n",
        "sts = len(sentences)\n",
        "model_copy.eval()\n",
        "with torch.no_grad():\n",
        "  if torch.cuda.is_available():\n",
        "    txt = txt.cuda()\n",
        "    txt_len = txt_len.cuda()\n",
        "  predictions = model_copy(txt, txt_len)\n",
        "  print(predictions)\n",
        "  print(torch.max(predictions, 1)[1].view(sts).data,\"\\n \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3V4eaCVFEf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "0c2633d6-6396-4b15-95c7-379f1cf4b664"
      },
      "source": [
        "# global testing\n",
        "attn_wts_test.size()#[batch, r, words]\n",
        "attns = attn_wts_test.permute(0,2,1)\n",
        "attns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0527],\n",
              "         [0.0624],\n",
              "         [0.1439],\n",
              "         [0.1679],\n",
              "         [0.5731]]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK53yfuf14aq"
      },
      "source": [
        "def make_batch(sent):\n",
        "  l=[]\n",
        "  m=[]\n",
        "  max = 0\n",
        "  for i in range(len(sent)):\n",
        "    ind = get_indices_sent(clean_str(sent[i]))\n",
        "    l.append(ind)\n",
        "    if len(ind)>max:\n",
        "      max=len(ind)\n",
        "    m.append(len(ind))\n",
        "\n",
        "  for i in range(len(l)):\n",
        "    length_sent = len(l[i])\n",
        "    if length_sent != max:\n",
        "      l[i].extend([TEXT.vocab.stoi[TEXT.pad_token]]*(max - length_sent))\n",
        "  # print(torch.LongTensor(l).size(),\"=====\",torch.LongTensor(m).size())\n",
        "  # print(torch.LongTensor(l),\"=====\",torch.LongTensor(m))\n",
        "  return torch.LongTensor(l), torch.LongTensor(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNEZGCvErsI5"
      },
      "source": [
        "---TESTING END---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoU2MsD0sybm"
      },
      "source": [
        "params = ['clip', 'batch', 'EPOCHS', 'lrate', 'wd', \n",
        "          'hid_dim','dropout_lstm','nlayers-lstm','bilstm','r', 'dropout_m1','#parameters',\n",
        "          'Epoch of best acc','best acc','best acc-loss','which fold']\n",
        "dfp = pd.DataFrame(columns=params)\n",
        "  \n",
        "def model_params(arr):\n",
        "  global dfp\n",
        "  dfp.loc[len(dfp)] = arr  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bXQuLF5u0T2"
      },
      "source": [
        "def build_criterion(): \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  criterion = criterion.to(device)\n",
        "  return criterion\n",
        "\n",
        "def build_model(word_embeddings):\n",
        "  vocab_dim = len(TEXT.vocab)\n",
        "  global flag;\n",
        "  embed_dim = 300\n",
        "  hid_dim= 300\n",
        "  dropout_lstm = 0.5\n",
        "  nlstm=2\n",
        "  SRC_PAD_IDX=TEXT.vocab.stoi[TEXT.pad_token]\n",
        "  bidirectional=True\n",
        "  intermediate_val_r = 1\n",
        "  dropout_m1 = 0.5\n",
        "  output_size = 2\n",
        "  model = MainNetwork(vocab_dim, embed_dim,word_embeddings,SRC_PAD_IDX, hid_dim,dropout_lstm,nlstm, bidirectional,intermediate_val_r,dropout_m1,output_size)\n",
        "  #model.apply(initialize_weights);\n",
        "  #model.embedding.weight.data.copy_(word_embeddings)\n",
        "  model = model.to(device)\n",
        "  if flag == True:\n",
        "    parms.extend([hid_dim,dropout_lstm,nlstm,bidirectional,intermediate_val_r,dropout_m1,count_parameters(model)])\n",
        "    flag=False\n",
        "\n",
        "  return model\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svr_UkFBnHDJ"
      },
      "source": [
        "#############WEIGHT INITIALIZATION###############\n",
        "\n",
        "def weights_init_XU(m):\n",
        "  if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "    nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "def weights_init_N(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        m.weight.data.normal_(0.0, 1)\n",
        "        #nn.init.normal_(m.weight.data)\n",
        "\n",
        "def weights_init_XN(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_normal_(m.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO2V62_tryy6"
      },
      "source": [
        "=== MAIN MODEL ===\r\n",
        "\r\n",
        "Insipiration from NMT model by Bahadanau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOJL31LcNwtJ"
      },
      "source": [
        "# [batch , text]\n",
        "class MainNetwork(nn.Module):\n",
        "  def __init__(self,vocab_dim, embed_dim,weights,SRC_PAD_IDX, hid_dim,dropout_lstm,nlstm, bidirectional,intermediate_val_r,dropout_m1,output_size):\n",
        "    super(MainNetwork,self).__init__();  \n",
        "    self.r = intermediate_val_r\n",
        "    self.hid_dim = hid_dim\n",
        "    self.dir = 2 if bidirectional else 1\n",
        "    self.embedding = nn.Embedding.from_pretrained(word_embeddings,padding_idx= SRC_PAD_IDX,freeze=True)\n",
        "    #print(\"########WORD EMBEDS##########\\n\", self.embedding.weight.data,\"\\n @@@@@@@@@@@@@\")\n",
        "    self.lstm = nn.LSTM(embed_dim, hid_dim,\n",
        "                        batch_first=True,\n",
        "                        dropout = 0 if nlstm < 2 else dropout_lstm,\n",
        "                        num_layers=nlstm,\n",
        "                        bidirectional=bidirectional);\n",
        "    ##--------For attention--------##\n",
        "    #self.W_l1 = nn.Linear(hid_dim, 350)\n",
        "    self.W_s2 = nn.Linear(hid_dim, self.r, bias=True) #r=1\n",
        "    self.fc_layer = nn.Linear(self.r*hid_dim, output_size)\n",
        "    #self.label = nn.Linear(2000, output_size) --> dont think needed\n",
        "    self.dropout = nn.Dropout(dropout_m1)\n",
        "\n",
        "\n",
        "  def attn_wt_matrix(self, lstm_out):\n",
        "    wM = self.W_s2(F.tanh(lstm_out))  #now output is  batch,seq_len, r, torch.nn.Tanh\n",
        "    wM = wM.permute(0, 2, 1) \n",
        "    attn_wts = F.softmax(wM, dim=2)\n",
        "    return attn_wts\n",
        "\n",
        "  def forward(self, text,text_lengths): # [batch, max_sent_len]  \n",
        "    global testing;\n",
        "    global attn_wts_test;\n",
        "    b = text.shape[0]\n",
        "    seq_len = text.shape[1]\n",
        "    embeds = self.dropout(self.embedding(text)) #[batch, max_len, embed_size]\n",
        "    embeds_packed = nn.utils.rnn.pack_padded_sequence(embeds, text_lengths, batch_first=True)\n",
        "    \n",
        "    # if batch_size is None:\n",
        "\t\t# \th_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda())\n",
        "\t\t# \tc_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda())\n",
        "\t\t# else:\n",
        "    h_0 = Variable(torch.zeros(2*2, b, self.hid_dim).cuda())\n",
        "    c_0 = Variable(torch.zeros(2*2, b, self.hid_dim).cuda())\n",
        "    \n",
        "    packed_out, (fh,fc) = self.lstm(embeds_packed,(h_0, c_0)) #[batch, max_len, hid_dim*2] ; hid_dim of lstm bec bi\n",
        "    #from the last layer of the LSTM\n",
        "    output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_out)\n",
        "    #The elements of output from padding tokens will be zero tensors (tensors where every element is zero)\n",
        "    output = output.permute(1,0,2)\n",
        "    output = output.view(b, seq_len, self.dir, self.hid_dim) \n",
        "    output = torch.sum(output, dim=2) #element-wise sum to combine theforward and backward pass outputs - See RP --> our H\n",
        "    attn_wts = self.attn_wt_matrix(output) #mentioned as ALPHA in RP\n",
        "    hidden_matrix = self.dropout(torch.bmm(attn_wts, output))\n",
        "\n",
        "    #FLATTEN OUT\n",
        "    fc_out = self.fc_layer(hidden_matrix.view(-1, hidden_matrix.size()[1]*hidden_matrix.size()[2])) #bec input to FC layer is r*hid_dim, output will be [batch, output_size]\n",
        "\n",
        "    if testing:\n",
        "      attn_wts_test = attn_wts#[batch, r, seq_len]\n",
        "      \n",
        "    return fc_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZZN7glsjFL_"
      },
      "source": [
        "def clip_gradient(model, clip_value):\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
        "    for p in params:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJu6AqWmPFTT"
      },
      "source": [
        "def training(model, iterator, criterion, batch_size,optimizer,clip):\n",
        "  # print(\"training \")\n",
        "  epoch_loss = 0.0\n",
        "  epoch_accuracy = 0.0\n",
        " \n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    texts,text_lengths = batch.text \n",
        "    target = batch.label.type(torch.LongTensor)\n",
        "    #print(\"TEXT SHAPE\", texts.shape,\"***\", text_lengths)#torch.Size([40, 9]) number, max_length\n",
        "\n",
        "    if  texts.shape[0]!=batch_size:\n",
        "      continue;\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      texts = texts.cuda()\n",
        "      target = target.cuda()    \n",
        "\n",
        "    optimizer.zero_grad() \n",
        "    \n",
        "    predictions_batch  =  model(texts, text_lengths) #[batch, output_size]\n",
        "    loss = criterion(predictions_batch, target)\n",
        "    num_corrects = (torch.max(predictions_batch, 1)[1].view(target.size()).data == target.data).float().sum()\n",
        "    acc = 100.0 * num_corrects/len(batch)\n",
        "\n",
        "    loss.backward()    \n",
        "    clip_gradient(model,clip)   \n",
        "    \n",
        "    optimizer.step()   \n",
        "    \n",
        "    #loss and accuracy\n",
        "    epoch_loss += loss.item()  \n",
        "    epoch_accuracy += acc.item()     \n",
        "    \n",
        "  return epoch_loss / len(iterator), epoch_accuracy / len(iterator)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOTx7WYdQGcZ"
      },
      "source": [
        "def evaluation(model, iterator, batch_size):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            text, text_lengths = batch.text\n",
        "\n",
        "            target = batch.label.type(torch.LongTensor)\n",
        "            if  text.shape[0]!=batch_size:\n",
        "              continue;\n",
        "            if torch.cuda.is_available():\n",
        "              text = text.cuda()\n",
        "              target = target.cuda()    \n",
        "\n",
        "            predictions = model(text, text_lengths)\n",
        "            loss = criterion(predictions, target)\n",
        "            num_corrects = (torch.max(predictions, 1)[1].view(target.size()).data == target.data).sum()\n",
        "            acc = 100.0 * num_corrects/len(batch)\n",
        "            total_epoch_loss += loss.item()\n",
        "            total_epoch_acc += acc.item()\n",
        "            \n",
        "    return total_epoch_loss/len(iterator), total_epoch_acc/len(iterator)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}